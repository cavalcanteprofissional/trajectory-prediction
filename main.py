# main.py
import warnings
warnings.filterwarnings('ignore')

import sys
import traceback
from pathlib import Path
import pandas as pd
import numpy as np

def initialize_project():
    """Inicializa o projeto e configura o path"""
    ROOT_DIR = Path(__file__).parent
    sys.path.insert(0, str(ROOT_DIR))
    
    # Criar diretÃ³rios necessÃ¡rios
    directories = ['data', 'logs', 'models', 'submissions', 'reports']
    for dir_name in directories:
        dir_path = ROOT_DIR / dir_name
        dir_path.mkdir(exist_ok=True)
    
    print(f"ğŸ“ DiretÃ³rio raiz: {ROOT_DIR}")
    return ROOT_DIR

def setup_logging():
    """Configura logging bÃ¡sico"""
    import logging
    
    # Configurar root logger
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('logs/pipeline.log')
        ]
    )
    
    # Reduzir verbosidade de alguns loggers
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    logging.getLogger('tensorflow').setLevel(logging.WARNING)
    
    return logging.getLogger(__name__)

def load_and_prepare_data(logger, use_sample=True):
    """Carrega e prepara os dados"""
    logger.info("ğŸ“Š CARREGANDO E PREPARANDO DADOS")
    
    try:
        from data.loader import DataLoader
        data_loader = DataLoader()
        train_data, test_data = data_loader.load_data(use_sample=use_sample)
        
        summary = data_loader.get_data_summary()
        logger.info(f"âœ… Dados carregados: {summary['train_samples']} train, {summary['test_samples']} test")
        
        return train_data, test_data
        
    except Exception as e:
        logger.error(f"âŒ Erro ao carregar dados: {e}")
        logger.info("ğŸ“ Criando dados de exemplo manualmente...")
        
        # Criar dados de exemplo mais variados
        n_train = 1000
        n_test = 200
        
        # Garantir variabilidade nos dados
        np.random.seed(42)
        
        def create_trajectory(n_points):
            """Cria uma trajetÃ³ria mais realista"""
            base_lat = 40.0 + np.random.uniform(-2, 2)
            base_lon = -73.0 + np.random.uniform(-2, 2)
            
            # Criar caminho com alguma direÃ§Ã£o
            lat_points = [base_lat]
            lon_points = [base_lon]
            
            for i in range(1, n_points):
                # Adicionar algum movimento direcional
                lat_points.append(lat_points[-1] + np.random.uniform(-0.01, 0.01))
                lon_points.append(lon_points[-1] + np.random.uniform(-0.01, 0.01))
            
            return lat_points, lon_points
        
        # Dados de treino
        train_records = []
        for i in range(n_train):
            n_points = np.random.randint(5, 20)
            lat_points, lon_points = create_trajectory(n_points)
            
            # Destino baseado na direÃ§Ã£o da trajetÃ³ria
            dest_lat = lat_points[-1] + (lat_points[-1] - lat_points[0]) * np.random.uniform(0.5, 2.0)
            dest_lon = lon_points[-1] + (lon_points[-1] - lon_points[0]) * np.random.uniform(0.5, 2.0)
            
            train_records.append({
                'trajectory_id': f'train_{i:04d}',
                'path_lat': str(lat_points),
                'path_lon': str(lon_points),
                'dest_lat': dest_lat,
                'dest_lon': dest_lon
            })
        
        train_data = pd.DataFrame(train_records)
        
        # Dados de teste
        test_records = []
        for i in range(n_test):
            n_points = np.random.randint(5, 20)
            lat_points, lon_points = create_trajectory(n_points)
            
            test_records.append({
                'trajectory_id': f'test_{i:04d}',
                'path_lat': str(lat_points),
                'path_lon': str(lon_points)
            })
        
        test_data = pd.DataFrame(test_records)
        
        logger.info(f"ğŸ“ Dados de exemplo criados: {len(train_data)} train, {len(test_data)} test")
        return train_data, test_data

def extract_features(logger, train_data, test_data):
    """Extrai features dos dados"""
    logger.info("ğŸ”§ EXTRAINDO FEATURES")
    
    try:
        from features.engineering import FeatureEngineer
        feature_engineer = FeatureEngineer()
        
        # Extrair features
        train_features = feature_engineer.extract_all_features(train_data)
        test_features = feature_engineer.extract_all_features(test_data)
        
        # Adicionar targets se existirem
        if 'dest_lat' in train_data.columns and 'dest_lon' in train_data.columns:
            train_features['dest_lat'] = train_data['dest_lat'].values
            train_features['dest_lon'] = train_data['dest_lon'].values
        
        logger.info(f"âœ… Features extraÃ­das: {train_features.shape[1]} features")
        
        return train_features, test_features
        
    except Exception as e:
        logger.error(f"âŒ Erro na extraÃ§Ã£o de features: {e}")
        
        # Features bÃ¡sicas como fallback
        def extract_simple_features(df):
            features = []
            for _, row in df.iterrows():
                # Parse bÃ¡sico
                try:
                    import ast
                    lat_list = ast.literal_eval(row['path_lat']) if isinstance(row['path_lat'], str) else []
                    lon_list = ast.literal_eval(row['path_lon']) if isinstance(row['path_lon'], str) else []
                except:
                    lat_list = []
                    lon_list = []
                
                feat = {
                    'start_lat': lat_list[0] if len(lat_list) > 0 else 40.0,
                    'start_lon': lon_list[0] if len(lon_list) > 0 else -73.0,
                    'end_lat': lat_list[-1] if len(lat_list) > 0 else 40.0,
                    'end_lon': lon_list[-1] if len(lon_list) > 0 else -73.0,
                    'mean_lat': np.mean(lat_list) if len(lat_list) > 0 else 40.0,
                    'mean_lon': np.mean(lon_list) if len(lon_list) > 0 else -73.0,
                    'std_lat': np.std(lat_list) if len(lat_list) > 0 else 0,
                    'std_lon': np.std(lon_list) if len(lon_list) > 0 else 0,
                    'num_points': len(lat_list)
                }
                features.append(feat)
            
            return pd.DataFrame(features)
        
        train_features = extract_simple_features(train_data)
        test_features = extract_simple_features(test_data)
        
        if 'dest_lat' in train_data.columns and 'dest_lon' in train_data.columns:
            train_features['dest_lat'] = train_data['dest_lat'].values
            train_features['dest_lon'] = train_data['dest_lon'].values
        
        logger.info(f"ğŸ“ Usando features simples: {train_features.shape[1]} features")
        
        return train_features, test_features

def prepare_training_data(logger, train_features, test_features):
    """Prepara dados para treinamento"""
    logger.info("ğŸ“ˆ PREPARANDO DADOS PARA TREINAMENTO")
    
    try:
        from sklearn.preprocessing import StandardScaler
        
        # Separar features e target
        target_cols = ['dest_lat', 'dest_lon'] if 'dest_lat' in train_features.columns else []
        
        if target_cols:
            feature_cols = [col for col in train_features.columns if col not in target_cols]
            X_train = train_features[feature_cols].values
            y_train = train_features[target_cols].values
        else:
            feature_cols = train_features.columns.tolist()
            X_train = train_features.values
            y_train = np.zeros((len(train_features), 2))  # Dummy target
        
        X_test = test_features[feature_cols].values
        
        # Verificar se hÃ¡ features
        if X_train.shape[1] == 0:
            logger.warning("âš  Nenhuma feature encontrada, criando features dummy")
            X_train = np.random.randn(len(train_features), 5)
            X_test = np.random.randn(len(test_features), 5)
            feature_cols = [f'feature_{i}' for i in range(5)]
        
        # Normalizar
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        logger.info(f"âœ… Dados preparados: X_train {X_train_scaled.shape}, X_test {X_test_scaled.shape}")
        
        return {
            'X_train': X_train_scaled,
            'y_train': y_train,
            'X_test': X_test_scaled,
            'feature_names': feature_cols,
            'scaler': scaler
        }
        
    except Exception as e:
        logger.error(f"âŒ Erro ao preparar dados: {e}")
        
        # Fallback
        n_features = 10
        return {
            'X_train': np.random.randn(len(train_features), n_features),
            'y_train': np.random.randn(len(train_features), 2),
            'X_test': np.random.randn(len(test_features), n_features),
            'feature_names': [f'feature_{i}' for i in range(n_features)],
            'scaler': None
        }

def train_model(logger, X_train, y_train):
    """Treina o modelo"""
    logger.info("ğŸ¤– TREINANDO MODELO")
    
    try:
        # Tentar vÃ¡rios modelos
        models = []
        
        # 1. RandomForest
        try:
            from sklearn.ensemble import RandomForestRegressor
            from sklearn.multioutput import MultiOutputRegressor
            
            rf_model = MultiOutputRegressor(
                RandomForestRegressor(
                    n_estimators=100,
                    max_depth=10,
                    min_samples_split=5,
                    random_state=42,
                    n_jobs=-1
                )
            )
            models.append(('RandomForest', rf_model))
        except ImportError:
            pass
        
        # 2. Gradient Boosting
        try:
            from sklearn.ensemble import GradientBoostingRegressor
            
            gb_model = MultiOutputRegressor(
                GradientBoostingRegressor(
                    n_estimators=100,
                    learning_rate=0.1,
                    max_depth=5,
                    random_state=42
                )
            )
            models.append(('GradientBoosting', gb_model))
        except ImportError:
            pass
        
        # 3. Linear Regression (fallback simples)
        try:
            from sklearn.linear_model import LinearRegression
            
            lr_model = MultiOutputRegressor(LinearRegression())
            models.append(('LinearRegression', lr_model))
        except ImportError:
            pass
        
        if not models:
            raise ImportError("Nenhum modelo disponÃ­vel")
        
        # Treinar e avaliar cada modelo
        best_model = None
        best_score = float('inf')
        
        for name, model in models:
            logger.info(f"ğŸ”„ Treinando {name}...")
            
            try:
                model.fit(X_train, y_train)
                
                # AvaliaÃ§Ã£o simples (MSE)
                from sklearn.metrics import mean_squared_error
                y_pred = model.predict(X_train)
                score = mean_squared_error(y_train, y_pred)
                
                logger.info(f"   {name}: MSE = {score:.6f}")
                
                if score < best_score:
                    best_score = score
                    best_model = (name, model)
                    
            except Exception as e:
                logger.warning(f"   {name} falhou: {e}")
        
        if best_model:
            name, model = best_model
            logger.info(f"âœ… Melhor modelo: {name} (MSE: {best_score:.6f})")
            return model
        else:
            raise Exception("Todos os modelos falharam")
        
    except Exception as e:
        logger.error(f"âŒ Erro no treinamento: {e}")
        
        # Modelo dummy que retorna a mÃ©dia
        class MeanModel:
            def __init__(self):
                self.mean_lat = None
                self.mean_lon = None
            
            def fit(self, X, y):
                if len(y) > 0:
                    self.mean_lat = np.mean(y[:, 0])
                    self.mean_lon = np.mean(y[:, 1])
                else:
                    self.mean_lat = 40.0
                    self.mean_lon = -73.0
                return self
            
            def predict(self, X):
                n = len(X)
                return np.column_stack([
                    np.full(n, self.mean_lat),
                    np.full(n, self.mean_lon)
                ])
        
        model = MeanModel()
        model.fit(X_train, y_train)
        logger.info(f"ğŸ“ Usando modelo mÃ©dio: ({model.mean_lat:.4f}, {model.mean_lon:.4f})")
        
        return model

def make_predictions(logger, model, X_test):
    """Faz prediÃ§Ãµes"""
    logger.info("ğŸ”® FAZENDO PREDIÃ‡Ã•ES")
    
    try:
        predictions = model.predict(X_test)
        logger.info(f"âœ… {len(predictions)} prediÃ§Ãµes geradas")
        return predictions
        
    except Exception as e:
        logger.error(f"âŒ Erro nas prediÃ§Ãµes: {e}")
        
        # PrediÃ§Ãµes dummy
        n = len(X_test)
        predictions = np.column_stack([
            np.full(n, 40.0 + np.random.uniform(-1, 1)),
            np.full(n, -73.0 + np.random.uniform(-1, 1))
        ])
        logger.info("ğŸ“ Usando prediÃ§Ãµes dummy")
        
        return predictions

def save_results(logger, ROOT_DIR, test_data, predictions):
    """Salva os resultados"""
    logger.info("ğŸ’¾ SALVANDO RESULTADOS")
    
    try:
        submissions_dir = ROOT_DIR / 'submissions'
        submissions_dir.mkdir(exist_ok=True)
        
        submission_df = pd.DataFrame({
            'trajectory_id': test_data['trajectory_id'].values,
            'latitude_pred': predictions[:, 0],
            'longitude_pred': predictions[:, 1]
        })
        
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        submission_file = submissions_dir / f'submission_{timestamp}.csv'
        
        submission_df.to_csv(submission_file, index=False)
        logger.info(f"âœ… SubmissÃ£o salva em: {submission_file}")
        
        # Mostrar estatÃ­sticas
        print("\n" + "="*60)
        print("ğŸ“Š ESTATÃSTICAS DAS PREDIÃ‡Ã•ES:")
        print("="*60)
        print(f"Total de prediÃ§Ãµes: {len(predictions)}")
        print(f"Latitude:  MÃ©dia = {predictions[:, 0].mean():.6f}, Std = {predictions[:, 0].std():.6f}")
        print(f"Longitude: MÃ©dia = {predictions[:, 1].mean():.6f}, Std = {predictions[:, 1].std():.6f}")
        print(f"Range Latitude:  [{predictions[:, 0].min():.6f}, {predictions[:, 0].max():.6f}]")
        print(f"Range Longitude: [{predictions[:, 1].min():.6f}, {predictions[:, 1].max():.6f}]")
        
        print("\nğŸ“‹ PRIMEIRAS 5 PREDIÃ‡Ã•ES:")
        print(submission_df.head())
        print()
        
        return submission_file
        
    except Exception as e:
        logger.error(f"âŒ Erro ao salvar resultados: {e}")
        return None

def main():
    """Pipeline principal do projeto"""
    
    # Inicializar
    ROOT_DIR = initialize_project()
    logger = setup_logging()
    
    logger.info("=" * 60)
    logger.info("ğŸš€ INICIANDO PIPELINE COMPLETO DE PREDIÃ‡ÃƒO")
    logger.info("=" * 60)
    
    try:
        # 1. Carregar dados
        train_data, test_data = load_and_prepare_data(logger, use_sample=True)
        
        # 2. Extrair features
        train_features, test_features = extract_features(logger, train_data, test_data)
        
        # 3. Preparar dados
        data_dict = prepare_training_data(logger, train_features, test_features)
        
        # 4. Treinar modelo
        model = train_model(logger, data_dict['X_train'], data_dict['y_train'])
        
        # 5. Fazer prediÃ§Ãµes
        predictions = make_predictions(logger, model, data_dict['X_test'])
        
        # 6. Salvar resultados
        submission_file = save_results(logger, ROOT_DIR, test_data, predictions)
        
        logger.info("=" * 60)
        logger.info("ğŸ‰ PIPELINE CONCLUÃDO COM SUCESSO!")
        
        if submission_file:
            logger.info(f"ğŸ“„ Arquivo gerado: {submission_file}")
            
        logger.info("=" * 60)
        
        return 0
        
    except Exception as e:
        logger.error(f"ğŸ’¥ ERRO CRÃTICO NO PIPELINE: {e}")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())