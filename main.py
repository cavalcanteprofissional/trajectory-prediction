# main.py
import warnings
warnings.filterwarnings('ignore')

import sys
import traceback
from pathlib import Path
import pandas as pd
import numpy as np
import subprocess
import os
import argparse
import json

def initialize_project():
    """Inicializa o projeto"""
    ROOT_DIR = Path(__file__).parent
    sys.path.insert(0, str(ROOT_DIR))
    
    try:
        from config import config
        print(f"Diretorio raiz: {config.ROOT_DIR}")
        print(f"Dados: {config.DATA_DIR}")
        print(f"Competicao: {config.KAGGLE_COMPETITION}")
        return config
        
    except ImportError as e:
        print(f"Erro ao carregar configuracoes: {e}")
        
        # Configura√ß√£o b√°sica como fallback
        ROOT_DIR = Path(__file__).parent
        
        directories = ['data', 'logs', 'models', 'submissions', 'reports']
        for dir_name in directories:
            dir_path = ROOT_DIR / dir_name
            dir_path.mkdir(exist_ok=True)
            print(f"Criado: {dir_path}")
        
        return type('Config', (), {
            'ROOT_DIR': ROOT_DIR, 
            'DATA_DIR': ROOT_DIR / 'data',
            'LOGS_DIR': ROOT_DIR / 'logs',
            'SUBMISSIONS_DIR': ROOT_DIR / 'submissions',
            'KAGGLE_COMPETITION': os.getenv('KAGGLE_COMPETITION', 'topicos-especiais-em-aprendizado-de-maquina-v2')
        })()

def setup_logging():
    """Configura logging sem emojis"""
    import logging
    
    # Criar diret√≥rio de logs
    logs_dir = Path('logs')
    logs_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(logs_dir / 'pipeline.log', encoding='utf-8')
        ]
    )
    
    # Reduzir verbosidade
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    
    return logging.getLogger(__name__)

def check_kaggle_cli():
    """Verifica se o Kaggle CLI est√° instalado e configurado"""
    try:
        result = subprocess.run(["kaggle", "--version"], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            print(f"‚úÖ Kaggle CLI detectado: {result.stdout.strip()}")
            return True
        else:
            print("‚ö†Ô∏è  Kaggle CLI encontrado mas com erro:")
            print(result.stderr)
            return False
    except FileNotFoundError:
        print("‚ùå Kaggle CLI n√£o encontrado.")
        print("   Instale com: pip install kaggle")
        print("   Configure com: kaggle configure")
        return False
    except Exception as e:
        print(f"‚ùå Erro ao verificar Kaggle CLI: {e}")
        return False

def submit_to_kaggle_automatically(submission_file, model_name, competition_name, logger):
    """Envia submiss√£o automaticamente para Kaggle via linha de comando"""
    try:
        # Mensagem de commit
        commit_message = f"Submissao automatica - Modelo: {model_name} - {competition_name}"
        
        # Verificar se Kaggle CLI est√° instalado
        if not check_kaggle_cli():
            logger.warning("Kaggle CLI n√£o est√° dispon√≠vel para submiss√£o autom√°tica")
            return False
        
        # Comando para submiss√£o
        cmd = [
            "kaggle", "competitions", "submit",
            "-c", competition_name,
            "-f", str(submission_file),
            "-m", commit_message
        ]
        
        logger.info(f"Enviando submiss√£o para Kaggle...")
        logger.info(f"Comando: {' '.join(cmd)}")
        
        # Executar submiss√£o
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info("‚úÖ Submiss√£o enviada com sucesso!")
            logger.info(f"Arquivo: {submission_file}")
            logger.info(f"Mensagem: {commit_message}")
            
            # Verificar status
            try:
                status_cmd = ["kaggle", "competitions", "submissions", "-c", competition_name]
                status_result = subprocess.run(status_cmd, capture_output=True, text=True)
                if status_result.returncode == 0:
                    logger.info("√öltimas submiss√µes:")
                    # Pegar apenas as primeiras linhas para n√£o poluir o log
                    lines = status_result.stdout.strip().split('\n')
                    for line in lines[:3]:
                        logger.info(f"  {line}")
            except Exception as status_error:
                logger.warning(f"N√£o foi poss√≠vel verificar status: {status_error}")
            
            return True
        else:
            logger.error(f"‚ùå Erro ao enviar submiss√£o:")
            logger.error(f"Stderr: {result.stderr}")
            return False
            
    except Exception as e:
        logger.error(f"Erro inesperado na submiss√£o autom√°tica: {e}")
        return False

def run_data_pipeline(logger, config, auto_submit=False):
    """Executa o pipeline completo de dados"""
    logger.info("=" * 60)
    logger.info("PIPELINE DE DADOS - TE APRENDIZADO DE MAQUINA")
    logger.info("=" * 60)
    
    try:
        # 1. Carregar dados
        logger.info("\n1. CARREGANDO DADOS")
        
        from data import DataLoader
        loader = DataLoader()
        
        # Verificar se dados existem
        data_exists = loader.ensure_data_exists(download_if_missing=True)
        
        if not data_exists:
            logger.warning("Nao foi possivel obter dados reais, usando dados de exemplo")
        
        # Carregar dados (tenta reais primeiro, depois exemplo)
        train_data, test_data = loader.load_data(use_sample_if_missing=True)
        
        summary = loader.get_data_summary()
        logger.info(f"Dados carregados:")
        logger.info(f"   ‚Ä¢ Train: {summary['train_samples']} amostras")
        logger.info(f"   ‚Ä¢ Test: {summary['test_samples']} amostras")
        logger.info(f"   ‚Ä¢ Tem target: {summary['has_target']}")
        
        # Mostrar primeiras linhas
        logger.info(f"\nPrimeira linha do train:")
        logger.info(f"   ID: {train_data.iloc[0]['trajectory_id']}")
        
        if 'dest_lat' in train_data.columns:
            logger.info(f"   Destino: ({train_data.iloc[0]['dest_lat']:.6f}, {train_data.iloc[0]['dest_lon']:.6f})")
        
        # 2. Detec√ß√£o de outliers
        # 2a. Limpeza inicial de dados inconsistentes / faltantes
        logger.info("\n2. LIMPEZA INICIAL DE DADOS (tratamento e filtragem)")
        try:
            from features.cleaning import clean_train_test
            logger.info("Aplicando limpeza conservadora nos dados (remover duplicatas, coer√ß√£o num√©rica, coordenadas imposs√≠veis, linhas sem destino)")
            train_data, test_data = clean_train_test(train_data, test_data)
            logger.info(f"   ‚Ä¢ Train ap√≥s limpeza: {len(train_data)} amostras")
            logger.info(f"   ‚Ä¢ Test ap√≥s limpeza: {len(test_data)} amostras")
        except Exception as e:
            logger.warning(f"Falha na etapa de limpeza inicial: {e}")

        logger.info("\n2b. DETECCAO DE OUTLIERS")
        
        # Ajustar limites geogr√°ficos para China e proximidades
        from features import OutlierDetector
        OutlierDetector.VALID_LAT_RANGE = (18.0, 54.0)  # Latitude da China: ~18¬∞ a 54¬∞ N
        OutlierDetector.VALID_LON_RANGE = (73.0, 135.0)  # Longitude da China: ~73¬∞ a 135¬∞ E
        
        outlier_detector = OutlierDetector(
            max_jump_distance_km=200.0,  # Reduzido: saltos >200km s√£o suspeitos
            max_speed_kmh=500.0,  # Reduzido: velocidades >500km/h s√£o improv√°veis
            contamination=0.02,  # Aumentado ligeiramente: 2%
            use_isolation_forest=False,  # Manter desabilitado
            use_geographic_bounds=False,  # Manter desabilitado
            max_outlier_percentage=0.10  # Aumentado: m√°ximo 10%
        )
        
        # Detectar outliers nos dados originais
        train_outliers_dict = outlier_detector.detect_all_outliers(
            train_data,
            use_geographic=True,  # Coordenadas inv√°lidas
            use_trajectory=True,  # HABILITADO: trajet√≥rias com saltos grandes
            use_target=True,  # Coordenadas inv√°lidas no target
            use_features=False  # Manter desabilitado por enquanto
        )
        
        # Combinar outliers (qualquer tipo de outlier)
        train_outliers_combined = outlier_detector.get_combined_outliers(
            train_outliers_dict, method='any'
        )
        
        # Gerar relat√≥rio
        outlier_report = outlier_detector.get_outlier_report(
            train_data, train_outliers_dict, train_outliers_combined
        )
        
        logger.info(f"Outliers detectados:")
        logger.info(f"   ‚Ä¢ Total: {outlier_report['total_outliers']} ({outlier_report['percentage_outliers']:.2f}%)")
        logger.info(f"   ‚Ä¢ Amostras limpas: {outlier_report['clean_samples']}")
        
        for outlier_type, stats in outlier_report['by_type'].items():
            logger.info(f"   ‚Ä¢ {outlier_type}: {stats['count']} ({stats['percentage']:.2f}%)")
        
        # Remover outliers do conjunto de treino
        n_before = len(train_data)
        
        # Prote√ß√£o adicional: N√ÉO remover dados se for mais que 2%
        outlier_percentage = train_outliers_combined.sum() / len(train_data) if len(train_data) > 0 else 0
        
        if outlier_percentage > 0.02:  # Apenas 2% m√°ximo
            logger.warning(f"‚ö†Ô∏è  {outlier_percentage*100:.1f}% dos dados foram marcados como outliers!")
            logger.warning("   Aplicando prote√ß√£o: removendo apenas coordenadas geogr√°ficas inv√°lidas...")
            
            # Usar apenas outliers geogr√°ficos (coordenadas inv√°lidas) - mais confi√°veis
            safe_outliers = pd.Series(False, index=train_data.index)
            if 'geographic' in train_outliers_dict:
                safe_outliers = safe_outliers | train_outliers_dict['geographic']
            
            # Adicionar apenas outliers de target (coordenadas inv√°lidas)
            if 'target' in train_outliers_dict:
                safe_outliers = safe_outliers | train_outliers_dict['target']
            
            train_outliers_combined = safe_outliers
            logger.info(f"   ‚Ä¢ Outliers seguros detectados: {safe_outliers.sum()} ({safe_outliers.sum()/len(train_data)*100:.1f}%)")
        
        train_data_clean = outlier_detector.remove_outliers(
            train_data, train_outliers_combined, inplace=False
        )
        n_after = len(train_data_clean)
        n_removed = n_before - n_after
        
        logger.info(f"\nRemovendo outliers do conjunto de treino:")
        logger.info(f"   ‚Ä¢ Antes: {n_before} amostras")
        logger.info(f"   ‚Ä¢ Depois: {n_after} amostras")
        logger.info(f"   ‚Ä¢ Removidas: {n_removed} amostras")
        
        # Verifica√ß√£o final: garantir que h√° dados suficientes
        if n_after == 0:
            logger.error("‚ùå ERRO: Todos os dados foram removidos! Usando dados originais sem remo√ß√£o de outliers.")
            train_data_clean = train_data.copy()
        
        train_data = train_data_clean
        
        # 3. Engenharia de features
        logger.info("\n3. ENGENHARIA DE FEATURES")
        
        from features import FeatureEngineer
        feature_engineer = FeatureEngineer()

        # Aplicar augmenta√ß√£o leve para robustez (jitter + rota√ß√µes pequenas)
        try:
            from features.augmentation import augment_dataframe
            logger.info("Aplicando augmentacao leve ao conjunto de treino (p=0.25)")
            train_data_aug = augment_dataframe(train_data, methods=['jitter', 'rotate'], p=0.25, seed=42)
        except Exception as e:
            logger.warning(f"Augmentation n√£o dispon√≠vel: {e}")
            train_data_aug = train_data
        
        train_features = feature_engineer.extract_all_features(train_data_aug)
        test_features = feature_engineer.extract_all_features(test_data)
        
        if 'dest_lat' in train_data.columns:
            train_features['dest_lat'] = train_data['dest_lat'].values
            train_features['dest_lon'] = train_data['dest_lon'].values
        
        logger.info(f"Features extraidas: {train_features.shape[1]} features")
        
        # Detectar outliers nas features (apenas se houver dados suficientes)
        if len(train_features) > 0:
            logger.info("\nDetectando outliers nas features...")
            
            # Garantir que train_features e train_data tenham os mesmos √≠ndices
            common_indices = train_features.index.intersection(train_data.index)
            if len(common_indices) != len(train_features) or len(common_indices) != len(train_data):
                logger.warning(f"   ‚ö†Ô∏è  √çndices n√£o alinhados. Reindexando...")
                train_features = train_features.loc[common_indices]
                train_data = train_data.loc[common_indices]
            
            # DESABILITADO: Detec√ß√£o de outliers nas features pode remover dados importantes
            # feature_outliers_dict = outlier_detector.detect_all_outliers(
            #     train_data,
            #     features_df=train_features,
            #     use_geographic=False,
            #     use_trajectory=False,
            #     use_target=False,
            #     use_features=True
            # )
            
            # N√ÉO remover outliers de features - manter todos os dados
            logger.info("   ‚ÑπÔ∏è  Detec√ß√£o de outliers nas features DESABILITADA (muito agressiva)")
            feature_outliers_combined = pd.Series(False, index=train_features.index)
        
        # Garantir que dest_lat e dest_lon est√£o nas features ap√≥s remo√ß√£o
        if 'dest_lat' in train_data.columns:
            train_features['dest_lat'] = train_data['dest_lat'].values
            train_features['dest_lon'] = train_data['dest_lon'].values
        
        # 4. Preparar dados para treinamento
        logger.info("\n4. PREPARANDO DADOS")
        
        # Preparar dados para treinamento com RobustScaler (mais resistente a outliers)
        prepared_data = feature_engineer.prepare_features_for_training(
            train_features, test_features, scaler_type='robust', use_local_target=True
        )
        
        # Armazenar pontos de refer√™ncia para convers√£o de volta (se usando coordenadas locais)
        test_starts_lat = test_features['start_lat'].values if 'start_lat' in test_features.columns else None
        test_starts_lon = test_features['start_lon'].values if 'start_lon' in test_features.columns else None
        
        logger.info(f"Dados preparados:")
        logger.info(f"   ‚Ä¢ X_train: {prepared_data['X_train'].shape}")
        logger.info(f"   ‚Ä¢ X_test: {prepared_data['X_test'].shape}")
        
        if 'y_train' in prepared_data:
            logger.info(f"   ‚Ä¢ y_train: {prepared_data['y_train'].shape}")
        
        # 5. Treinar modelo
        logger.info("\n5. TREINANDO MODELO")

        from training import ModelTrainer
        trainer = ModelTrainer()

        # Criar modelos com par√¢metros otimizados
        from models import ModelFactory
        model_factory = ModelFactory(n_samples=len(prepared_data['X_train']))

        # Usar apenas modelos priorit√°rios para velocidade
        models = model_factory.create_all_models(
            priority_only=True,  # Usa apenas modelos priorit√°rios
            include_ensemble=True,  # Inclui ensemble
            n_features=prepared_data['X_train'].shape[1]
        )

        # Se existirem resultados do Optuna, aplicar os melhores par√¢metros aos modelos correspondentes
        optuna_file = Path('reports') / 'optuna_short_results.json'
        if optuna_file.exists():
            try:
                with open(optuna_file, 'r', encoding='utf-8') as f:
                    optuna_res = json.load(f)

                for model_name, info in optuna_res.items():
                    best_params = info.get('best_params')
                    if best_params and model_name in models:
                        logger.info(f"Aplicando params Optuna em {model_name}: {best_params}")
                        try:
                            models[model_name] = model_factory.create_model(model_name, params=best_params, n_features=prepared_data['X_train'].shape[1])
                        except Exception as e:
                            logger.warning(f"Falha ao criar {model_name} com params optuna: {e}")
            except Exception as e:
                logger.warning(f"N√£o foi poss√≠vel ler optuna_short_results.json: {e}")

        # IMPORTANTE: Valida√ß√£o cruzada usa APENAS dados de treino (train.csv)
        # O test.csv √© usado APENAS para predi√ß√µes finais, nunca para treino ou valida√ß√£o
        logger.info("‚ö†Ô∏è  VALIDA√á√ÉO CRUZADA: Usando apenas dados de TREINO (train.csv)")
        logger.info("‚ö†Ô∏è  TEST.CSV ser√° usado APENAS para predi√ß√µes finais")
        
        # Treinar com valida√ß√£o cruzada (10 folds) - APENAS train.csv
        groups = prepared_data.get('groups', None)
        y_unit = 'meters' if test_starts_lat is not None else 'degrees'
        refs_lat = train_features['start_lat'].values if y_unit == 'meters' else None
        refs_lon = train_features['start_lon'].values if y_unit == 'meters' else None
        results = trainer.train_all_models(
            prepared_data['X_train'],  # APENAS train.csv
            prepared_data['y_train'],   # APENAS train.csv
            models,
            cv_folds=10,
            groups=groups,
            y_unit=y_unit,
            refs_lat=refs_lat,
            refs_lon=refs_lon
        )
        
        # Treinar modelo final
        final_model_info = trainer.train_final_model(
            prepared_data['X_train'],
            prepared_data['y_train']
        )
        
        logger.info(f"Modelo treinado: {final_model_info['model_name']}")
        
        # 6. Fazer predi√ß√µes
        logger.info("\n6. FAZENDO PREDICOES")
        logger.info("‚ö†Ô∏è  Usando test.csv APENAS para predi√ß√µes finais (n√£o usado em treino/valida√ß√£o)")
        
        final_model = final_model_info['model']
        predictions = final_model.predict(prepared_data['X_test'])  # APENAS test.csv para predi√ß√µes
        
        # Se usando coordenadas locais, converter de volta para lat/lon
        if test_starts_lat is not None and test_starts_lon is not None:
            logger.info("Convertendo predi√ß√µes de coordenadas locais para lat/lon...")
            dest_lats = []
            dest_lons = []
            for i in range(len(predictions)):
                lat, lon = FeatureEngineer.local_xy_to_latlon(
                    test_starts_lat[i], test_starts_lon[i], predictions[i, 0], predictions[i, 1]
                )
                dest_lats.append(lat)
                dest_lons.append(lon)
            predictions = np.column_stack([dest_lats, dest_lons])
        
        logger.info(f"{len(predictions)} predicoes geradas")
        
        # 7. Salvar submiss√£o
        logger.info("\n7. SALVANDO SUBMISSAO")
        
        from submission import SubmissionGenerator
        submission_gen = SubmissionGenerator()
        
        submission_file = submission_gen.generate_submission(
            test_ids=test_data['trajectory_id'].values,
            predictions=predictions,
            model_name=final_model_info['model_name'],
            description=f"Modelo {final_model_info['model_name']} - {config.KAGGLE_COMPETITION}",
            test_df=test_data
        )
        
        logger.info(f"Submissao salva: {submission_file}")
        
        # 8. Submiss√£o autom√°tica ao Kaggle (se solicitado)
        submission_success = False
        if auto_submit:
            logger.info("\n8. ENVIANDO SUBMISSAO AO KAGGLE")
            submission_success = submit_to_kaggle_automatically(
                submission_file,
                final_model_info['model_name'],
                config.KAGGLE_COMPETITION,
                logger
            )
            
            if submission_success:
                logger.info("‚úÖ Submissao enviada ao Kaggle com sucesso!")
            else:
                logger.warning("‚ö†Ô∏è  Falha ao enviar submissao ao Kaggle")
        
        # 9. Mostrar estat√≠sticas
        print("\n" + "=" * 60)
        print("ESTATISTICAS FINAIS")
        print("=" * 60)
        print(f"Modelo usado: {final_model_info['model_name']}")
        print(f"Total de predicoes: {len(predictions)}")
        print(f"Range Latitude: [{predictions[:, 0].min():.6f}, {predictions[:, 0].max():.6f}]")
        print(f"Range Longitude: [{predictions[:, 1].min():.6f}, {predictions[:, 1].max():.6f}]")
        
        if trainer.best_model_info:
            print(f"\nMelhor modelo na validacao: {trainer.best_model_info['model_name']}")
            print(f"   Erro medio: {trainer.best_model_info['mean_error']:.4f} km")
        
        print("\nPrimeiras 5 predicoes:")
        preview_df = pd.DataFrame({
            'trajectory_id': test_data['trajectory_id'].values[:5],
            'latitude': predictions[:5, 0],
            'longitude': predictions[:5, 1]
        })
        print(preview_df.to_string(index=False))
        
        # 10. Salvar relat√≥rio
        report_file = config.ROOT_DIR / 'reports' / 'pipeline_report.txt'
        report_file.parent.mkdir(exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"Relatorio do Pipeline - {config.KAGGLE_COMPETITION}\n")
            f.write("=" * 50 + "\n")
            f.write(f"Data: {pd.Timestamp.now()}\n")
            f.write(f"Modelo final: {final_model_info['model_name']}\n")
            f.write(f"Amostras de treino (apos remocao de outliers): {len(train_data)}\n")
            f.write(f"Amostras de teste: {len(test_data)}\n")
            f.write(f"Features: {train_features.shape[1]}\n")
            f.write(f"Outliers removidos: {outlier_report['total_outliers']} ({outlier_report['percentage_outliers']:.2f}%)\n")
            f.write(f"Arquivo de submissao: {submission_file}\n")
            f.write(f"Submissao enviada: {'SIM' if submission_success else 'NAO'}\n")
            
            if trainer.best_model_info:
                f.write(f"Melhor erro na validacao: {trainer.best_model_info['mean_error']:.4f} km\n")
        
        logger.info(f"Relatorio salvo: {report_file}")
        
        return {
            'success': True,
            'submission_file': submission_file,
            'model_name': final_model_info['model_name'],
            'predictions': predictions,
            'submitted': submission_success,
            'best_model_error': trainer.best_model_info['mean_error'] if trainer.best_model_info else None
        }
        
    except Exception as e:
        logger.error(f"Erro no pipeline: {e}", exc_info=True)
        return {
            'success': False,
            'error': str(e)
        }

def get_latest_submission():
    """Obt√©m o arquivo de submiss√£o mais recente"""
    submissions_dir = Path("submissions")
    if not submissions_dir.exists():
        return None
    
    csv_files = list(submissions_dir.glob("submission_*.csv"))
    if not csv_files:
        return None
    
    # Ordenar por data de modifica√ß√£o (mais recente primeiro)
    csv_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return str(csv_files[0])

def submit_only_mode(competition_name, message="", logger=None):
    """Modo apenas para submeter arquivo existente"""
    latest_file = get_latest_submission()
    
    if not latest_file:
        print("‚ùå Nenhum arquivo de submiss√£o encontrado!")
        print(f"Procure em: submissions/")
        return False
    
    # Usar logger se dispon√≠vel, sen√£o print
    log_func = logger.info if logger else print
    
    if not message:
        file_name = os.path.basename(latest_file)
        # Extrair nome do modelo do arquivo
        if '_' in file_name:
            model_name = file_name.split('_')[1] if len(file_name.split('_')) > 1 else "Desconhecido"
            message = f"Submissao automatica - Modelo: {model_name}"
        else:
            message = "Submissao automatica"
    
    log_func(f"üì§ Enviando arquivo mais recente: {os.path.basename(latest_file)}")
    log_func(f"üìù Mensagem: {message}")
    
    import logging
    return submit_to_kaggle_automatically(latest_file, "√öltimo modelo", competition_name, 
                                         logger or logging.getLogger(__name__))

def main():
    """Fun√ß√£o principal"""
    
    # Configurar argumentos de linha de comando
    parser = argparse.ArgumentParser(
        description='Pipeline de predi√ß√£o de trajet√≥rias - TE Aprendizado de M√°quina',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  %(prog)s                    # Executa pipeline sem enviar
  %(prog)s --submit           # Executa pipeline e envia para Kaggle
  %(prog)s --submit-only      # Apenas envia o √∫ltimo arquivo
  %(prog)s --submit-only -m "Minha mensagem"  # Envia com mensagem customizada
        """
    )
    parser.add_argument('--submit', action='store_true', 
                       help='Executa pipeline completo e envia submiss√£o para Kaggle')
    parser.add_argument('--submit-only', action='store_true',
                       help='Apenas envia o √∫ltimo arquivo de submiss√£o (n√£o executa pipeline)')
    parser.add_argument('--cv-folds', type=int, default=10,
                       help='N√∫mero de folds para valida√ß√£o cruzada (default: 10)')
    parser.add_argument('-m', '--message', type=str, default='',
                       help='Mensagem customizada para submiss√£o Kaggle')
    parser.add_argument('--model', type=str, default='',
                       help='Modelo espec√≠fico para usar (opcional)')
    
    args = parser.parse_args()
    
    # Inicializar
    config = initialize_project()
    logger = setup_logging()
    
    print("=" * 60)
    print(f"TRAJECTORY PREDICTION - {config.KAGGLE_COMPETITION}")
    print("=" * 60)
    print(f"Dados: {config.DATA_DIR}")
    print(f"Logs: {config.LOGS_DIR}")
    print(f"Submissoes: {config.SUBMISSIONS_DIR}")
    
    if args.submit_only:
        print(f"Modo: APENAS SUBMISS√ÉO")
        print()
        
        # Verificar Kaggle CLI
        if not check_kaggle_cli():
            return 1
        
        # Executar apenas submiss√£o
        success = submit_only_mode(
            config.KAGGLE_COMPETITION, 
            args.message if args.message else "",
            logger
        )
        
        if success:
            print("\n‚úÖ Submiss√£o conclu√≠da!")
            return 0
        else:
            print("\n‚ùå Falha na submiss√£o!")
            return 1
    
    else:
        print(f"Submissao automatica: {'SIM' if args.submit else 'NAO'}")
        print()
        
        # Executar pipeline completo
        result = run_data_pipeline(logger, config, auto_submit=args.submit)
        
        if result['success']:
            print("\n" + "=" * 60)
            print("‚úÖ PIPELINE CONCLUIDO COM SUCESSO!")
            print("=" * 60)
            print(f"üìÑ Submissao: {result['submission_file']}")
            print(f"ü§ñ Modelo: {result['model_name']}")
            
            if result.get('best_model_error'):
                print(f"üìä Erro medio: {result['best_model_error']:.4f} km")
            
            if result.get('submitted'):
                print("üöÄ Submiss√£o enviada automaticamente ao Kaggle!")
            else:
                # Instru√ß√µes para envio manual
                if args.submit:
                    print("‚ö†Ô∏è  Submiss√£o N√ÉO foi enviada (verifique logs acima)")
                
                print("\nPARA ENVIAR AO KAGGLE:")
                print("Op√ß√£o 1 - Execute novamente com --submit:")
                print(f"   python main.py --submit")
                print("\nOp√ß√£o 2 - Apenas envie o √∫ltimo arquivo:")
                print(f"   python main.py --submit-only")
                print("\nOp√ß√£o 3 - Comando manual:")
                print(f"   kaggle competitions submit -c {config.KAGGLE_COMPETITION} \\")
                print(f"     -f {result['submission_file']} \\")
                print(f"     -m \"Submissao automatica - {result['model_name']}\"")
            
            print("\n" + "=" * 60)
            return 0
        else:
            print("\n" + "=" * 60)
            print("‚ùå PIPELINE FALHOU")
            print("=" * 60)
            print(f"Erro: {result.get('error', 'Desconhecido')}")
            
            # Mostrar traceback se dispon√≠vel
            if 'traceback' in result:
                print("\nTraceback:")
                print(result['traceback'])
            
            return 1

if __name__ == "__main__":
    sys.exit(main())